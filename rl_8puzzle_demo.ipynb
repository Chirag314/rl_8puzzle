{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL 8-Puzzle Demo\n",
    "\n",
    "This notebook demonstrates the trained Q-learning agent for the 3×3 8-puzzle.\n",
    "\n",
    "- If a saved Q-table exists at `rl_8puzzle/q_table.pkl`, it will be loaded.\n",
    "- Otherwise, a smaller training run will be executed and saved.\n",
    "- Then we visualize a greedy solution from a random scrambled start state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "from rl_8puzzle.env import EightPuzzleEnv, GOAL_STATE, ACTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(state):\n",
    "    \"\"\"Pretty-print a 3x3 board.\"\"\"\n",
    "    for r in range(3):\n",
    "        row = state[r * 3:(r + 1) * 3]\n",
    "        print(\" \".join(\"_\" if x == 0 else str(x) for x in row))\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_q(path=\"rl_8puzzle/q_table.pkl\"):\n",
    "    \"\"\"Load Q-table if it exists; otherwise train a smaller one.\"\"\"\n",
    "    p = Path(path)\n",
    "    if p.exists():\n",
    "        print(f\"Loading existing Q-table from {p}…\")\n",
    "        with p.open(\"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    print(\"Q-table not found. Training a small one (this may take a minute)…\")\n",
    "    from rl_8puzzle.train_q_learning import train, save_q\n",
    "\n",
    "    Q = train(\n",
    "        num_episodes=20000,   # smaller than full training but good enough\n",
    "        max_steps=80,\n",
    "        scramble_moves=20,\n",
    "    )\n",
    "    save_q(Q, p)\n",
    "    print(f\"Saved new Q-table to {p}.\")\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = load_q()\n",
    "\n",
    "env = EightPuzzleEnv(scramble_moves=20)\n",
    "start_state = env.reset()\n",
    "\n",
    "print(\"Start state:\")\n",
    "print_board(start_state)\n",
    "\n",
    "states = [start_state]\n",
    "rewards = []\n",
    "\n",
    "for step in range(80):\n",
    "    state = env.state\n",
    "    qs = [Q.get((state, a), 0.0) for a in ACTIONS]\n",
    "    best_idx = max(range(len(ACTIONS)), key=lambda i: qs[i])\n",
    "    action = ACTIONS[best_idx]\n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    states.append(next_state)\n",
    "    rewards.append(reward)\n",
    "\n",
    "    if done:\n",
    "        print(f\"\\nSolved in {step + 1} moves. Final reward: {reward}.\")\n",
    "        break\n",
    "else:\n",
    "    print(\"\\nDid not reach goal within the step limit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrajectory:\")\n",
    "for i, s in enumerate(states):\n",
    "    print(f\"Step {i}\")\n",
    "    print_board(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
